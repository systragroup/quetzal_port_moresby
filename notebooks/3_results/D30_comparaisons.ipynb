{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # for automation and parallelization: set manual to false when run by a launcher\n",
    "import json\n",
    " \n",
    "default = {'scenario': 'port-moresby', 'training_folder':'../..'} # Default execution parameters\n",
    "manual, argv = (True, default) if 'ipykernel' in sys.argv[0] else (False, dict(default, **json.loads(sys.argv[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "sys.path.insert(0, r'../../../quetzal') # Add path to quetzal\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from numba import jit, njit\n",
    "import numba as nb\n",
    "from quetzal.model import stepmodel\n",
    "from shapely.geometry import LineString\n",
    "from quetzal.io.gtfs_reader.importer import get_epsg\n",
    "from quetzal.io import excel\n",
    "on_lambda = bool(os.environ.get('AWS_EXECUTION_ENV'))\n",
    "num_cores = nb.config.NUMBA_NUM_THREADS\n",
    "print('num cores:',num_cores)\n",
    "from syspy.spatial import spatial, utils\n",
    "io_engine= 'pyogrio' if on_lambda else 'pyogrio' #or fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = argv['scenario']\n",
    "\n",
    "on_lambda = bool(os.environ.get('AWS_EXECUTION_ENV'))\n",
    "print('On Lambda : ', on_lambda)\n",
    "\n",
    "training_folder = argv['training_folder']\n",
    "input_folder = training_folder +r'/inputs/'\n",
    "\n",
    "if not on_lambda:\n",
    "    scenario_folder = training_folder + '/scenarios/' + scenario  + '/inputs/'\n",
    "    output_folder = training_folder + '/scenarios/' + scenario + '/outputs/'\n",
    "    model_folder = training_folder + '/scenarios/' + scenario  + '/model/'\n",
    "else:\n",
    "    scenario_folder = input_folder\n",
    "    output_folder = training_folder + '/outputs/'\n",
    "    model_folder = training_folder + '/model/'\n",
    "print('input folder: ', input_folder)\n",
    "print('output folder: ', output_folder)\n",
    "print('scen folder : ', scenario_folder)\n",
    "print('model folder : ', model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'params' in argv.keys():\n",
    "    scenario = argv['params']['general']['scenario'] #'params':{'general':{'scenario':'ref2023'}}\n",
    "    var = excel.read_var(file=input_folder+'parameters.xlsx', scenario=scenario, return_ancestry=False)\n",
    "    var.update(pd.DataFrame.from_dict(argv['params'], orient=\"index\").stack())\n",
    "else:\n",
    "    var = excel.read_var(file=input_folder+'parameters.xlsx', scenario=scenario, return_ancestry=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_up(n, decimals=0):\n",
    "    multiplier = 10**decimals\n",
    "    return math.ceil(n * multiplier) / multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = stepmodel.read_zippedpickles(model_folder +'logit_assignment')\n",
    "sm.segments = ['car_owner', 'pt_captive'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = sm.change_epsg(4326,'degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_provided = os.path.isfile((training_folder +'/scenarios/{scen}_projet/model/logit_assignment'.format(scen = scenario)))\n",
    "if not comp_provided:\n",
    "    end_of_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = stepmodel.read_zippedpickles(training_folder +'/scenarios/{scen}_projet/model/logit_assignment'.format(scen = scenario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.links.loc[new.links['agency_id'] == 'QUENEDI'].groupby('route_id')['boardings'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_utility =(new.utilities.set_index(['origin','destination'])['pt']-sm.utilities.set_index(['origin','destination'])['pt']).replace(np.inf, np.nan).replace(-np.inf, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_utility.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_utility.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_boardings_agency = pd.concat([sm.links.groupby(['agency_id'])['boardings'].sum(), new.links.groupby(['agency_id'])['boardings'].sum()],axis=1, keys = ['ref', 'new'])\n",
    "comp_boardings_agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_boardings_mode = pd.concat([sm.links.groupby(['route_type'])['boardings'].sum(), new.links.groupby(['route_type'])['boardings'].sum()],axis=1, keys = ['boardings_ref', 'boardings_new'])\n",
    "comp_boardings_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_boardings_trip = pd.concat([sm.links.groupby('trip_id')['boardings'].sum(), new.links.groupby('trip_id')['boardings'].sum()],axis=1, keys = ['ref', 'new'])\n",
    "comp_boardings_trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_boardings_route = pd.concat([sm.links.groupby('route_id')['boardings'].sum(), new.links.groupby('route_id')['boardings'].sum()],axis=1, keys = ['ref', 'new'])\n",
    "comp_boardings_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_var(to_plot, \n",
    "                    voy_h_sm=0,\n",
    "                    voy_h_new=0, \n",
    "                    title=None):\n",
    "\n",
    "    systra_color = [\"#D22328\", \"#559BB4\", \"#91A564\", \"#DC9100\", \"#8C4B7D\", \"#A08C69\",\"#647D6E\", \"#5A7382\", \"#64411E\", \"#A00037\", \"#643C5A\"]\n",
    "    to_plot = to_plot.iloc[1:18]\n",
    "    to_plot.index = ['{} - {} min'.format(i*5, (i+1)*5) for i in to_plot.index]\n",
    "    to_plot.columns = ['Projet', 'Référence']\n",
    "\n",
    "    to_plot.plot(kind='bar', figsize=[20, 10], fontsize=15, color=systra_color, zorder=3)\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.grid(axis='y',zorder=0)\n",
    "    plt.title(title, loc='left', fontsize=18, fontweight=\"bold\")\n",
    "    plt.legend(['Projet: ({} voy.h)'.format(int(np.round(voy_h_sm, -2))), 'Référence ({} voy.h)'.format(int(np.round(voy_h_new, -2)))], loc='upper right', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.los['time_class'] = sm.los['time'].apply(lambda d: int(divmod(d,300)[0]))\n",
    "new.los['time_class'] = new.los['time'].apply(lambda d: int(divmod(d,300)[0]))\n",
    "voy_h_sm = (sm.los['volume']*sm.los['time']/3600).sum()\n",
    "voy_h_new = (new.los['volume']*new.los['time']/3600).sum()\n",
    "time_class_sm = sm.los.groupby('time_class')['volume'].sum()\n",
    "time_class_new = new.los.groupby('time_class')['volume'].sum()  \n",
    "to_plot = pd.merge(time_class_sm, time_class_new, right_index=True, left_index=True)\n",
    "plot_time_var(to_plot,\n",
    "                    voy_h_sm=voy_h_sm,\n",
    "                    voy_h_new=voy_h_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = new.links.copy()\n",
    "links.groupby(\"trip_id\").agg({'headway':\"mean\", 'route_type' : 'first',\"length\":\"sum\"})\n",
    "links[\"vehicules\"] = 10740/links[\"headway\"]\n",
    "vkm_new = links.groupby(\"route_type\").agg({'vehicules':\"sum\", \"length\":\"sum\"})\n",
    "links['vkm_new'] = (links[\"vehicules\"]/1000) * links[\"length\"]\n",
    "vkm_new = links.groupby('route_type').agg({'vkm_new':\"sum\"})\n",
    "\n",
    "links = sm.links.copy()\n",
    "links.groupby(\"trip_id\").agg({'headway':\"mean\", 'route_type' : 'first',\"length\":\"sum\"})\n",
    "links[\"vehicules\"] = 10740/links[\"headway\"]\n",
    "vkm_ref = links.groupby(\"route_type\").agg({'vehicules':\"sum\", \"length\":\"sum\"})\n",
    "links['vkm_ref'] = (links[\"vehicules\"]/1000) * links[\"length\"]\n",
    "vkm_ref = links.groupby('route_type').agg({'vkm_ref':\"sum\"})\n",
    "\n",
    "vkm = pd.concat([vkm_ref, vkm_new], axis=1)\n",
    "vkm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([vkm, comp_boardings_mode], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_of_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
