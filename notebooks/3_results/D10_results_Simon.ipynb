{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367d1d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # for automation and parallelization: set manual to false when run by a launcher\n",
    "import json\n",
    " \n",
    "default = {'scenario': 'port-moresby','training_folder':'../..'} # Default execution parameters\n",
    "manual, argv = (True, default) if 'ipykernel' in sys.argv[0] else (False, dict(default, **json.loads(sys.argv[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a52d442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTables is not installed. No support for HDF output.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "sys.path.insert(0, r'../../../quetzal') # Add path to quetzal\n",
    "\n",
    "from quetzal.model import stepmodel\n",
    "from syspy.syspy_utils.pandas_utils import groupby_weighted_average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5b12c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loaded_links: 100%|██████████| 38/38 [00:03<00:00, 10.77it/s]   \n",
      "loaded_links: 100%|██████████| 38/38 [00:02<00:00, 16.53it/s]    \n"
     ]
    }
   ],
   "source": [
    "scenario = argv['scenario']\n",
    "\n",
    "output_folder = '../../scenarios/{scen}_projet/outputs/'.format(scen = scenario)\n",
    "filepath = '../../scenarios/{scen}_projet/model/logit_assignment'.format(scen = scenario)\n",
    "pro = stepmodel.read_zippedpickles(filepath)\n",
    "filepath = '../../scenarios/{scen}/model/logit_assignment'.format(scen = scenario)\n",
    "ref = stepmodel.read_zippedpickles(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5bbef6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutput_folder\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_folder' is not defined"
     ]
    }
   ],
   "source": [
    "output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "output_folder = '../../scenarios/houston_projet_60/outputs/'\n",
    "filepath = '../../scenarios/houston_projet_60/model/logit_assignment'\n",
    "pro = stepmodel.read_zippedpickles(filepath)\n",
    "filepath = '../../scenarios/houston/model/logit_assignment'\n",
    "ref = stepmodel.read_zippedpickles(filepath)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b030f32",
   "metadata": {},
   "source": [
    "# Zones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7afcf0",
   "metadata": {},
   "source": [
    "## Part TC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6d0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vol(self):\n",
    "    p = self.probabilities.set_index(['origin', 'destination', 'segment'])\n",
    "    v = self.volumes.set_index(['origin', 'destination']).stack()   \n",
    "    v.index.names = ['origin', 'destination', 'segment']\n",
    "\n",
    "    return p.mul(v, axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_vol_origin = compute_vol(pro).groupby('origin')[['car', 'pt']].sum()\n",
    "ref_vol_origin = compute_vol(ref).groupby('origin')[['car', 'pt']].sum()\n",
    "\n",
    "pro_share = pro_vol_origin.div(pro_vol_origin.sum(axis=1), axis=0)*100\n",
    "ref_share = ref_vol_origin.div(ref_vol_origin.sum(axis=1), axis=0)*100\n",
    "\n",
    "pro_share.columns = [c + '_share_pro' for c in pro_share.columns]\n",
    "ref_share.columns = [c + '_share_ref' for c in ref_share.columns]\n",
    "\n",
    "pro.zones = pro.zones.join(pro_share).join(ref_share)\n",
    "\n",
    "pro.zones['car_share_diff'] = (pro.zones['car_share_pro'] - pro.zones['car_share_ref']).clip(upper=0)\n",
    "pro.zones['pt_share_diff']  = (pro.zones['pt_share_pro']  - pro.zones['pt_share_ref']).clip(lower=0.0)\n",
    "pro.zones['pt_share_diff_rel'] = (pro.zones['pt_share_diff']/pro.zones['pt_share_ref']).fillna(0.0)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6514dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro.zones['pt_share_diff'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ccba42",
   "metadata": {},
   "source": [
    "### PT Time Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best pro time per OD\n",
    "pro_min_time = pro.pt_los.sort_values('gtime').drop_duplicates(['origin', 'destination'])\n",
    "pro_min_time = pro_min_time.set_index(['origin', 'destination'])['gtime']\n",
    "\n",
    "# Best ref time per OD\n",
    "ref_min_time = ref.pt_los.sort_values('gtime').drop_duplicates(['origin', 'destination'])\n",
    "ref_min_time = ref_min_time.set_index(['origin', 'destination'])['gtime']\n",
    "\n",
    "# Utility Improvement per OD\n",
    "diff_time = (pro_min_time - ref_min_time).clip(upper=0)/60\n",
    "diff_time.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f2ba63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2793d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pro.volumes.set_index(['origin', 'destination']).sum(axis=1)\n",
    "v.name = 'volume'\n",
    "\n",
    "time_improv = pd.concat([diff_time, v], axis=1)\n",
    "\n",
    "time_impov_origin = groupby_weighted_average(time_improv.reset_index(), groupby='origin', columns='gtime', weight='volume')\n",
    "time_impov_origin.rename(columns = {'gtime': 'time_improv'}, inplace=True)\n",
    "\n",
    "pro.zones = pro.zones.join(time_impov_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5527e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_impov_origin.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#self.links['volume_total'] = self.links['volume'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = pro.copy()\n",
    "\n",
    "\n",
    "self.links.drop(columns='load', inplace=True)\n",
    "self.nodes.drop(columns='load', inplace=True)\n",
    "self.step_assignment(\n",
    "    road = True,\n",
    "    boardings=True,\n",
    "    boarding_links=True,\n",
    "    alightings=True,\n",
    "    alighting_links=True,\n",
    "    transfers=True,\n",
    ")\n",
    "self.links.rename(columns={'volume': 'load_tot'})\n",
    "self.links.fillna(0.0, inplace=True)\n",
    "self.nodes.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e79d76e",
   "metadata": {},
   "source": [
    "# Arboresence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11076adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_set = set(pro.links[pro.links['agency_id'] == 'QUENEDI'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece71f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = pro.copy()\n",
    "\n",
    "self.links.drop(columns='load', inplace=True,errors='ignore')\n",
    "self.nodes.drop(columns='load', inplace=True,errors='ignore')\n",
    "self.step_assignment(\n",
    "    road = True,\n",
    "    boardings=True,\n",
    "    boarding_links=True,\n",
    "    alightings=True,\n",
    "    alighting_links=True,\n",
    "    transfers=True,\n",
    ")\n",
    "self.links.rename(columns={'volume': 'load_tot'})\n",
    "self.links.fillna(0.0, inplace=True)\n",
    "self.nodes.fillna(0.0, inplace=True)\n",
    "self.road_links.columns = [str(c) for c in self.road_links.columns]\n",
    "self.road_links['load_tot'] =  self.road_links[\"('volume', 'pt')\"] \n",
    "self.road_links.drop(columns=[\"('volume', 'pt')\",\"('volume', 'car')\"],inplace=True)\n",
    "\n",
    "\n",
    "self.los['boarding_links'] = self.los['boarding_links'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "self.los = self.los[self.los['boarding_links'].apply(lambda x: len(set(x).intersection(links_set)) > 0)]\n",
    "\n",
    "self.links.drop(columns='load', inplace=True,errors='ignore')\n",
    "self.nodes.drop(columns='load', inplace=True,errors='ignore')\n",
    "self.step_assignment(\n",
    "    road = True,\n",
    "    boardings=True,\n",
    "    boarding_links=True,\n",
    "    alightings=True,\n",
    "    alighting_links=True,\n",
    "    transfers=True,\n",
    ")\n",
    "self.links.rename(columns={'volume': 'load'})\n",
    "self.links.fillna(0.0, inplace=True)\n",
    "self.nodes.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790fffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert self.links.loc[self.links['route_type'] != 'bus']['road_link_list'].apply(len).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f553ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.links.loc[self.links['route_type'] == 'bus']['volume'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0ede7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_links = self.road_links.copy()\n",
    "road_links.columns=[str(c) for c in road_links.columns]\n",
    "road_links['load'] = road_links[\"('volume', 'pt')\"]\n",
    "road_links.dropna(subset=['load_tot'], inplace=True)\n",
    "road_links = gpd.GeoDataFrame(road_links, crs=pro.zones.crs).to_crs(epsg=4326)\n",
    "road_links.drop('index', axis=1).to_file(os.path.join(output_folder, 'road_links.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cb8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.GeoDataFrame(self.links, crs=pro.zones.crs).to_crs(epsg=4326)\n",
    "links.dropna(subset=['volume'], inplace=True)\n",
    "links.drop('road_link_list', axis=1).to_file(os.path.join(output_folder, 'links_arbo.geojson'))\n",
    "\n",
    "nodes = gpd.GeoDataFrame(self.nodes, crs=pro.zones.crs).to_crs(epsg=4326)\n",
    "nodes.dropna(subset=['boardings', 'alightings'], how='all' , inplace=True)\n",
    "nodes.to_file(os.path.join(output_folder, 'nodes_arbo.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.GeoDataFrame(pro.links, crs=pro.zones.crs).to_crs(epsg=4326)\n",
    "links.dropna(subset=['load'], inplace=True)\n",
    "links.drop('road_link_list', axis=1).to_file(os.path.join(output_folder, 'links.geojson'))\n",
    "\n",
    "links = gpd.GeoDataFrame(pro.links, crs=pro.zones.crs).to_crs(epsg=4326)\n",
    "nodes.dropna(subset=['boardings', 'alightings'], how='all', inplace=True)\n",
    "nodes.to_file(os.path.join(output_folder, 'nodes.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a3c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = pro.zones.to_crs(epsg=4326)\n",
    "zone['geometry'] = zone['geometry'].apply(lambda g: g.simplify(1e-3))\n",
    "zone.to_crs(epsg=4326).to_file(os.path.join(output_folder, 'zones.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_of_notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quetzal_env",
   "language": "python",
   "name": "quetzal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
