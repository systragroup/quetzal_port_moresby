{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71ccff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_folder': '../../scenarios/port-moresby', 'params': {'catchment_radius': {'bus': '500', 'subway': '800', 'rail': '1000'}}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "catchment_radius={'bus':'500','subway':'800','rail':'1000'}\n",
    "\n",
    "params = {'catchment_radius':catchment_radius}\n",
    "\n",
    "default = {'training_folder': '../../scenarios/port-moresby', 'params':params} # Default execution parameters\n",
    "manual, argv = (True, default) if 'ipykernel' in sys.argv[0] else (False, dict(default, **json.loads(sys.argv[1])))\n",
    "print(argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b5db61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numba threads 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "sys.path.insert(0, r'../../../quetzal') # Add path to quetzal\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, LineString\n",
    "from syspy.spatial.spatial import add_geometry_coordinates, nearest, points_in_polygon\n",
    "from syspy.spatial.utils import get_epsg\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from typing import Literal\n",
    "from numba import jit\n",
    "import numba as nb\n",
    "#num_cores = 1\n",
    "print('numba threads',nb.config.NUMBA_NUM_THREADS)\n",
    "\n",
    "on_lambda = bool(os.environ.get('AWS_EXECUTION_ENV'))\n",
    "io_engine = 'pyogrio' if on_lambda else 'fiona'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc057466",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from quetzal_cyclops\n",
    "def zones_nearest_node(zones,nodes,drop_duplicates=False):\n",
    "    # getting zones centroids\n",
    "    centroid = zones.copy()\n",
    "    centroid['geometry'] = centroid.centroid\n",
    "    # finding nearest node\n",
    "    neigh = nearest(centroid, nodes, n_neighbors=1).rename(columns={'ix_one': 'zone_index', 'ix_many': 'node_index'})\n",
    "    zone_node_dict = neigh.set_index('zone_index')['node_index'].to_dict()\n",
    "    centroid['node_index'] = centroid.index.map(zone_node_dict.get)\n",
    "    #print('max_distance found: ', neigh['distance'].max())\n",
    "    # check for duplicated nodes. if there is. drop the duplicated zones.\n",
    "    if drop_duplicates:\n",
    "        if len(centroid.drop_duplicates('node_index')) != len(centroid):\n",
    "            print('there is zones associates to the same road_node')\n",
    "            # duplicated = centroid[centroid['node_index'].duplicated()]['node_index'].values\n",
    "            print('dropping zones: ')\n",
    "            print(centroid[centroid['node_index'].duplicated()].index.values)\n",
    "            centroid = centroid.drop_duplicates('node_index')\n",
    "    return centroid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2595e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quetzal.engine.pathfinder_utils import simple_routing, sparse_matrix, get_path\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "\n",
    "@jit(nopython=True)\n",
    "def _unstack(mat):\n",
    "    # return non inf values in mat as [[row,col,val],[row,col,val]]. so, [o,d,val].\n",
    "    # pd.DataFrame of this gives us [origin, destination, value] as columns\n",
    "    row, col = np.where(np.isfinite(mat))\n",
    "    res = np.zeros((len(row),3))\n",
    "    for it in nb.prange(len(col)):\n",
    "        i=row[it]\n",
    "        j=col[it]\n",
    "        d=mat[i,j]\n",
    "        res[it]=[i,j,d]\n",
    "    return res\n",
    "\n",
    "def routing(origin, destination, links, weight_col='time', dijkstra_limit=np.inf):\n",
    "    mat, node_index = sparse_matrix(links[['a', 'b', weight_col]].values)\n",
    "    index_node = {v: k for k, v in node_index.items()}\n",
    "    # liste des origines pour le dijkstra\n",
    "    origin_sparse = [node_index[x] for x in origin]\n",
    "    origin_dict =  {i:val for i,val in enumerate(origin_sparse)}\n",
    "    # list des destinations \n",
    "    destination_sparse = [node_index[x] for x in destination]\n",
    "    destination_dict =  {i:val for i,val in enumerate(destination_sparse)}\n",
    "    # dijktra on the road network from node = incices to every other nodes.\n",
    "    # from b to a.\n",
    "    dist_matrix = dijkstra(\n",
    "        csgraph=mat,\n",
    "        directed=True,\n",
    "        indices=origin_sparse,\n",
    "        return_predecessors=False,\n",
    "        limit=dijkstra_limit\n",
    "    )\n",
    "    # remove non-used destination\n",
    "    dist_matrix = dist_matrix[:,destination_sparse]\n",
    "    # unstack amtrix\n",
    "    dist_matrix = pd.DataFrame(_unstack(dist_matrix),columns=['origin', 'destination', weight_col])\n",
    "    # rename origin and destination with original indexes.\n",
    "    dist_matrix['origin'] = dist_matrix['origin'].apply(lambda x: index_node.get(origin_dict.get(x)))\n",
    "    dist_matrix['destination'] = dist_matrix['destination'].apply(lambda x: index_node.get(destination_dict.get(x)))\n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb087e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catchment_dist(link: gpd.GeoDataFrame, catchment_radius: dict, default: float=500):\n",
    "    route_type = link['route_type'].unique()\n",
    "    if len(route_type)>1:\n",
    "        print('multiple route type for a single route_id.. using first one for catchment radius')\n",
    "    route_type = route_type[0]\n",
    "    return catchment_radius.get(route_type, default)\n",
    "\n",
    "\n",
    "def nearest_radius(one, many, radius=100,to_crs=None):\n",
    "    try:\n",
    "        # Assert df_many.index.is_unique\n",
    "        assert one.index.is_unique\n",
    "        assert many.index.is_unique\n",
    "    except AssertionError:\n",
    "        msg = 'Index of one or many should not contain duplicates'\n",
    "        print(msg)\n",
    "        warnings.warn(msg)\n",
    "    many = add_geometry_coordinates(many, columns=['x_geometry', 'y_geometry'], to_crs=to_crs)\n",
    "    one = add_geometry_coordinates(one, columns=['x_geometry', 'y_geometry'], to_crs=to_crs)\n",
    "    \n",
    "    x = many[['x_geometry', 'y_geometry']].values\n",
    "    # Fit Nearest neighbors model\n",
    "    #nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ball_tree').fit(x)\n",
    "    nbrs = NearestNeighbors(radius=radius,algorithm='ball_tree').fit(x)\n",
    "\n",
    "    y = one[['x_geometry', 'y_geometry']].values\n",
    "\n",
    "    #distances, indices = nbrs.kneighbors(y,return_distance=True)\n",
    "    distances, indices = nbrs.radius_neighbors(y, radius = radius, return_distance=True)\n",
    "\n",
    "    indices = pd.DataFrame(indices)\n",
    "    indices = pd.DataFrame(indices.stack(), columns=['index_nn']).reset_index().rename(\n",
    "        columns={'level_0': 'ix_one', 'level_1': 'rank'}\n",
    "    )\n",
    "    indices['distances'] = distances\n",
    "    return indices\n",
    "\n",
    "def create_mesh(zones: gpd.GeoDataFrame ,step: float = 0.01) -> gpd.GeoDataFrame:\n",
    "    '''\n",
    "    create a mesh in the zones total bbox at every step (in the units of the zones crs)\n",
    "    step: degree if crs=4326, else meters. 0.01 deg ~ 1km\n",
    "    '''\n",
    "    x_max, y_max = zones.bounds.max()[['maxx','maxy']].values\n",
    "    x_min, y_min = zones.bounds.min()[['minx','miny']].values\n",
    "\n",
    "    points = []\n",
    "    x = x_min\n",
    "    while x<x_max:\n",
    "        y = y_min\n",
    "        while y<y_max:\n",
    "            points.append(Point(x,y))\n",
    "            y += step\n",
    "        x += step\n",
    "    points = gpd.GeoDataFrame(geometry=points,crs=zones.crs)\n",
    "    points.index.name='index'\n",
    "    return points\n",
    "\n",
    "# https://stackoverflow.com/questions/36399381/whats-the-fastest-way-of-checking-if-a-point-is-inside-a-polygon-in-python\n",
    "\n",
    "\n",
    "\n",
    "def population_to_mesh(population: gpd.GeoDataFrame,\n",
    "                       mesh: gpd.GeoDataFrame = None,\n",
    "                       step: float = 0.01,\n",
    "                       col: str = 'population', \n",
    "                       fill_missing: Literal['centroid', 'nearest', None] = 'centroid') ->  gpd.GeoDataFrame:\n",
    "    '''\n",
    "    create a mesh in the zones total bbox at every step (in the units of the zones crs)\n",
    "    and assign the population to each node equaly (if 2 node in a zone. they have each 50% of the population)\n",
    "    population:\n",
    "        geodataframe with total population by zones ans zones geomerty\n",
    "     mesh:\n",
    "        road nodes for example. if None. it will be created with equal step (variable step.)\n",
    "    step: \n",
    "        if mesh is None, Distance between each point degree if crs=4326, else meters. 0.01 deg ~ 1km\n",
    "    col:\n",
    "        column name with data to aggregation (population)\n",
    "    fill_missing: 'centroid', 'nearest', or None\n",
    "        centroid: zones centroid with no mesh node inside will be added to the mesh\n",
    "        nearest: zones population with no mesh point inside will be added to the nearest mesh point.\n",
    "    '''\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    population=population.copy()\n",
    "    if population.index.name != 'index':\n",
    "        population.index.name = 'index'\n",
    "    # use existing mesh (points .geosjon) or create one.\n",
    "    if mesh is not None:\n",
    "        # we need numerical indexes. also,\n",
    "        # new nodes will be added (new index) for zones with no points inside.\n",
    "        points = mesh.copy()\n",
    "        points = points.reset_index(names='node_index')\n",
    "        points.index.name='index'\n",
    "    else:\n",
    "        points = create_mesh(population, step=step)\n",
    "        \n",
    "    points_coords = np.array([point.coords[0] for point in points['geometry'].values])\n",
    "    \n",
    "    population['nodes'] = population['geometry'].apply(lambda x: points_in_polygon(points_coords,x))\n",
    "    \n",
    "    nodes = population.reset_index()[['index','nodes',col]].copy()\n",
    "    nodes = nodes.explode('nodes').dropna()\n",
    "    print(len(nodes[nodes['nodes'].duplicated()]),'nodes in multiple zones. will be match to a single zone.')\n",
    "    \n",
    "    \n",
    "    zone_index_dict = nodes.set_index('nodes')['index'].to_dict()\n",
    "    points['zone'] = points.index.map(zone_index_dict)\n",
    "\n",
    "    pop_dict = nodes.set_index('nodes')[col].to_dict()\n",
    "    points[col] = points.index.map(pop_dict)\n",
    "    points = points.dropna()\n",
    "    \n",
    "    # get number of points per zones. divide population equaly between each points\n",
    "    len_dict = points.groupby('zone')[col].agg(len).to_dict()\n",
    "    points['num_points'] = points['zone'].apply(lambda x:len_dict.get(x))\n",
    "    points[col] = points[col] / points['num_points']\n",
    "    points = points.drop(columns = ['num_points'])\n",
    "    \n",
    "    print(len(population) - len(points['zone'].unique()),'unfounded zones')\n",
    "    \n",
    "    zones_list = points['zone'].unique()\n",
    "    unfounded_zones = population.loc[~population.index.isin(zones_list)][['geometry',col]]\n",
    "    if fill_missing == 'centroid':\n",
    "        print('Unfound zones centroid will be added to mesh')\n",
    "        # append unfounded zones centroids as in mesh\n",
    "        unfounded_zones['geometry'] = unfounded_zones.centroid\n",
    "        unfounded_zones = unfounded_zones.reset_index().rename(columns={'index':'zone'})\n",
    "        points = pd.concat([points,unfounded_zones]).reset_index(drop=True)\n",
    "        points.index.name='index'\n",
    "    elif fill_missing == 'nearest':\n",
    "        print('unfound zone will be added to nearest mesh node. zone_index will be lost')\n",
    "        unfounded_zones = zones_nearest_node(unfounded_zones,points)\n",
    "        pop_to_append = unfounded_zones.groupby('node_index')[[col]].sum()\n",
    "\n",
    "        points = points.merge(pop_to_append,left_index=True,right_index=True,how='left')\n",
    "        points[col+'_y'] = points[col+'_y'].fillna(0)\n",
    "\n",
    "        points[col] = points[col+'_x'] + points[col+'_y']\n",
    "        points = points.drop(columns=[col+'_x', col+'_y'])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    points.index.name='index'\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5475f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acf_distances(nodes: gpd.GeoDataFrame, \n",
    "                      mesh: gpd.GeoDataFrame, \n",
    "                      crs:int,\n",
    "                      max_dist: float = 3000) -> gpd.GeoDataFrame:\n",
    "    '''\n",
    "    with nearest kneibor in a radius.\n",
    "    for pt node in nodes, get all mesh nodes in a distance < max_dist\n",
    "    \n",
    "    return gpd.Geodateframe with [node_index, mesh_index, distances, population]\n",
    "    '''\n",
    "\n",
    "    node_dist = nearest_radius(nodes, mesh, radius=max_dist, to_crs=crs)\n",
    "    node_dist = node_dist.rename(columns={'ix_one': 'node_index','index_nn':'mesh_index'}).drop(columns='rank')\n",
    "\n",
    "    nodes_index_dict = nodes.reset_index()['index'].to_dict()\n",
    "    node_dist['node_index'] = node_dist['node_index'].apply(lambda x: nodes_index_dict.get(x))\n",
    "\n",
    "    node_dist = node_dist.explode(['mesh_index','distances'])\n",
    "    population_dict = mesh['population'].to_dict()\n",
    "    node_dist['population'] = node_dist['mesh_index'].apply(lambda x: population_dict.get(x))\n",
    "    return node_dist\n",
    "\n",
    "def get_routing_distances(nodes: gpd.GeoDataFrame, \n",
    "                         rnodes: gpd.GeoDataFrame, \n",
    "                         rlinks: gpd.GeoDataFrame, \n",
    "                         mesh: gpd.GeoDataFrame, \n",
    "                         weight_col:str = 'length', \n",
    "                         dijkstra_limit: float = np.inf) -> gpd.GeoDataFrame:\n",
    "    '''\n",
    "    with dijktra on road network.\n",
    "    for pt node in nodes, get all mesh nodes in a distance < max_dist. can be change with weight_col\n",
    "    ex: weight_col = 'time', and dijkstra_limit = 120secs\n",
    "    \n",
    "    return gpd.Geodateframe with [node_index, mesh_index, distances, population]\n",
    "    '''\n",
    "\n",
    "    # transform PT nodes to nearest road nodes\n",
    "    node_to_rnode_df = zones_nearest_node(nodes,rnodes)[['node_index']]\n",
    "\n",
    "    node_rnodes_dict = node_to_rnode_df['node_index'].to_dict()\n",
    "    rnodes_node_dict = node_to_rnode_df.reset_index().groupby('node_index').agg(list)['index'].to_dict()\n",
    "\n",
    "    # there may be multiples nodes pointing to the same rnode. so rnodes_node_dict values are lists.\n",
    "    # need to added them back at the end when we go from rnode to nodes\n",
    "    origins = list(set(node_rnodes_dict.values()))\n",
    "    destinations = mesh['node_index'].values\n",
    "    mat = routing(origins, destinations, rlinks, weight_col=weight_col, dijkstra_limit=dijkstra_limit)\n",
    "\n",
    "    mat = mat.merge(mesh.reset_index()[['index','node_index','population']],left_on='destination',right_on='node_index',how='left')\n",
    "    mat = mat.drop(columns=['destination','node_index']).rename(columns={'index':'mesh_index'})\n",
    "\n",
    "    mat['origin'] = mat['origin'].apply(lambda x: rnodes_node_dict.get(x))\n",
    "    mat = mat.explode('origin')\n",
    "    mat = mat.rename(columns={'origin':'node_index', weight_col:'distances'})\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c740a4",
   "metadata": {},
   "source": [
    "# Folders stucture and params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbbcb7a",
   "metadata": {},
   "source": [
    "everything is on S3 (nothing on ECR) so no direct input folder. just scenarios/{scen}/inputs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ade8441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e405b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = argv['training_folder']\n",
    "input_folder = os.path.join(base_folder,'inputs/')\n",
    "pt_folder  = os.path.join(input_folder,'pt/')\n",
    "road_folder = os.path.join(input_folder,'road/')\n",
    "od_folder =  os.path.join(input_folder,'od/')\n",
    "\n",
    "output_folder = os.path.join(base_folder,'outputs/')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "model_folder = os.path.join(input_folder, 'model/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa37cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_radius = argv['params' ]['catchment_radius']\n",
    "catchment_radius = {k:float(v) for k,v in catchment_radius.items()}\n",
    "default_catchment_radius = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b11c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdd032bd",
   "metadata": {},
   "source": [
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a674100",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file(pt_folder + 'links.geojson',engine=io_engine) \n",
    "nodes = gpd.read_file(pt_folder + 'nodes.geojson',engine=io_engine)\n",
    "links = links.set_index('index')\n",
    "nodes = nodes.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c5c4543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population? True\n"
     ]
    }
   ],
   "source": [
    "population_file = os.path.join(input_folder, 'zones.geojson')\n",
    "population_file_provided = os.path.isfile(population_file)\n",
    "if population_file_provided :\n",
    "    population = gpd.read_file(population_file, engine=io_engine)\n",
    "    if 'index' in population.columns:\n",
    "        population = population.set_index('index')\n",
    "    else:\n",
    "        population.index.name='index'\n",
    "    assert 'density' in population.columns, 'need density column. in km2'\n",
    "    assert population.crs == 4326, 'population.geojson CRS must be EPSG:4326'\n",
    "print('population?',population_file_provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac965c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnodes? True\n"
     ]
    }
   ],
   "source": [
    "rnodes_file = os.path.join(road_folder, 'road_nodes.geojson')\n",
    "rnodes_file_provided = os.path.isfile(rnodes_file)\n",
    "if rnodes_file_provided:\n",
    "    rnodes = gpd.read_file(os.path.join(road_folder, 'road_nodes.geojson'), engine=io_engine)\n",
    "    rnodes = rnodes.set_index('index')\n",
    "    rlinks = gpd.read_file(os.path.join(road_folder, 'road_links.geojson'), engine=io_engine)\n",
    "    rlinks = rlinks.set_index('index')\n",
    "print('rnodes?',rnodes_file_provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6071cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "od? True\n"
     ]
    }
   ],
   "source": [
    "od_file = os.path.join(od_folder, 'od.geojson')\n",
    "od_file_provided = os.path.isfile(od_file)\n",
    "if od_file_provided:\n",
    "    od_test = gpd.read_file(od_file, engine=io_engine)\n",
    "    if 'name' not in od_test.columns:\n",
    "        od_test['name'] = od_test['index']\n",
    "    od_test['name'] = od_test['name'].fillna(od_test['index'].astype(str))\n",
    "print('od?',od_file_provided)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f6a33b",
   "metadata": {},
   "source": [
    "# population preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20859122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df034d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43808/550055817.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroid = [*LineString(nodes.centroid.values).centroid.coords][0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32755"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find meters CRS\n",
    "centroid = [*LineString(nodes.centroid.values).centroid.coords][0]\n",
    "crs = get_epsg(centroid[1],centroid[0])\n",
    "crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8178d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "if population_file_provided : \n",
    "    population['area (km2)'] = population.to_crs(crs).area*1e-6\n",
    "    population['area (km2)'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "283a2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "if population_file_provided :\n",
    "    population['population'] = population['density']*population['area (km2)']\n",
    "    population['population'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13601281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "220bbb67",
   "metadata": {},
   "source": [
    "# population mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6f6fe3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using road_nodes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 nodes in multiple zones. will be match to a single zone.\n",
      "3 unfounded zones\n",
      "unfound zone will be added to nearest mesh node. zone_index will be lost\n"
     ]
    }
   ],
   "source": [
    "if not population_file_provided:\n",
    "    mesh = gpd.GeoDataFrame(index=[0],data={'zone':'centroid','population':0},geometry=[Point(centroid[0],centroid[1])])\n",
    "    mesh.index.name = 'index'\n",
    "    mesh.crs=4326\n",
    "    if rnodes_file_provided:\n",
    "        mesh['node_index'] = rnodes.index[0]\n",
    "elif rnodes_file_provided:\n",
    "    # use rnodes as mesh.\n",
    "    print('using road_nodes')\n",
    "    mesh = population_to_mesh(population, mesh=rnodes, step=0.005, col='population', fill_missing='nearest')\n",
    "else:\n",
    "    # create a mesh\n",
    "    #0.01 = 1km 0.005 = 500m\n",
    "    mesh = population_to_mesh(population, step=0.005, col = 'population', fill_missing='centroid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a276040",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.to_file(output_folder + 'population_mesh.geojson',driver='GeoJSON',engine=io_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbafa49",
   "metadata": {},
   "source": [
    "# catchment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aae1e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find TC nodes to mesh distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac854281",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist = max(max(catchment_radius.values()),default_catchment_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffc2ca97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using road_nodes\n"
     ]
    }
   ],
   "source": [
    "if rnodes_file_provided:\n",
    "    print('using road_nodes')\n",
    "    node_dist = get_routing_distances(nodes, rnodes, rlinks, mesh, 'length', max_dist)\n",
    "else:\n",
    "    node_dist = get_acf_distances(nodes, mesh, crs, max_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d9cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3480e8ac",
   "metadata": {},
   "source": [
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ed69263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num route_id: 19\n",
      "num route_type: 2\n"
     ]
    }
   ],
   "source": [
    "print('num route_id:',len(links['route_id'].unique()))\n",
    "print('num route_type:',len(links['route_type'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc317930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init results dfs\n",
    "df_route_id = pd.DataFrame(index=links['route_id'].unique())\n",
    "df_route_id.index.name='route_id'\n",
    "\n",
    "df_route_type = pd.DataFrame(index=links['route_type'].unique())\n",
    "df_route_type.index.name='route_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45bc4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_catchment(col='route_id'):\n",
    "    #get all nodes with col filter\n",
    "    link = links.groupby(col)[['a','b','route_type']].agg({'a':set,'b':set,'route_type':'first'})\n",
    "    link['node'] = link.apply(lambda row: row['a'].union(row['b']), axis=1)\n",
    "    link = link.drop(columns=['a','b'])\n",
    "    # add catchment radius for the route_type\n",
    "    link['catchment_radius'] = link['route_type'].apply(lambda x: catchment_radius.get(x,default_catchment_radius))\n",
    "\n",
    "    col_exist = col == 'route_type' # cannot explode if index == route_type (a column)\n",
    "    link = link.explode('node').reset_index(drop=col_exist)\n",
    "    link = node_dist.merge(link, left_on='node_index', right_on='node')\n",
    "    #filter by distance\n",
    "    link = link[link['distances'] <= link['catchment_radius']]\n",
    "    #drop duplicated mesh nodes (we count only one time)\n",
    "    link = link.drop_duplicates(subset=['mesh_index',col],keep='first')\n",
    "\n",
    "    return link.groupby(col)['population'].sum().to_dict()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e18e10d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337174.1815326074\n"
     ]
    }
   ],
   "source": [
    "res = get_catchment('route_id')\n",
    "\n",
    "df_route_id['catchment'] = res\n",
    "print(sum([item for key,item in res.items()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06d98402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238307.75238749522\n"
     ]
    }
   ],
   "source": [
    "res = get_catchment('route_type')\n",
    "\n",
    "df_route_type['catchment'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35b71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ff69b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    links['network']=True\n",
    "    res=[]\n",
    "    dists = [0,1,10,20,50,100,250,500,800,1000]\n",
    "    for dist in dists:\n",
    "        col='network'\n",
    "        link = links.groupby(col)[['a','b','route_type']].agg({'a':set,'b':set,'route_type':'first'})\n",
    "        link['node'] = link.apply(lambda row: row['a'].union(row['b']), axis=1)\n",
    "        link = link.drop(columns=['a','b'])\n",
    "        # add catchment radius for the route_type\n",
    "        link['catchment_radius'] =dist\n",
    "\n",
    "        col_exist = col == 'route_type' # cannot explode if index == route_type (a column)\n",
    "        link = link.explode('node').reset_index(drop=col_exist)\n",
    "        link = node_dist.merge(link, left_on='node_index', right_on='node')\n",
    "        #filter by distance\n",
    "        link = link[link['distances'] <= link['catchment_radius']]\n",
    "        #drop duplicated mesh nodes (we count only one time)\n",
    "        link = link.drop_duplicates(subset=['mesh_index',col],keep='first')\n",
    "        volume = link['population'].sum()\n",
    "        res.append(volume)\n",
    "    plt.plot(dists,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2a4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de5d12fd",
   "metadata": {},
   "source": [
    "# frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f251696",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['frequency'] = 1/links['headway']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3829349f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.0\n"
     ]
    }
   ],
   "source": [
    "res = (links.groupby('route_id')['frequency'].agg(np.nanmean)*3600).to_dict()\n",
    "\n",
    "df_route_id['frequency (veh/hours)'] = res\n",
    "print(np.nansum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3035415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.661087866108787\n"
     ]
    }
   ],
   "source": [
    "res = (links.groupby('route_type')['frequency'].agg(np.nanmean)*3600).to_dict()\n",
    "\n",
    "df_route_type['frequency (veh/hours)'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1017844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.0\n"
     ]
    }
   ],
   "source": [
    "link = (links.groupby(['route_id','trip_id'])[['frequency']].agg(np.nanmean)*3600)\n",
    "res = link.reset_index().set_index('route_id')['frequency'].to_dict()\n",
    "print(np.nansum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99bf3c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n"
     ]
    }
   ],
   "source": [
    "link = (links.groupby(['route_type','trip_id'])[['frequency']].agg(np.nanmean)*3600)\n",
    "res = link.reset_index().set_index('route_type')['frequency'].to_dict()\n",
    "print(np.nansum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a9b56e",
   "metadata": {},
   "source": [
    "# operational Fleet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d73f2028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fleet(col='route_id'):\n",
    "    link = links.groupby([col,'trip_id'])[['time','frequency']].agg({'time':np.nansum,'frequency':np.nanmean})\n",
    "    link['fleet'] = np.ceil(link['frequency'] * link['time'])\n",
    "    return link.reset_index().groupby(col)['fleet'].agg(np.nansum).to_dict()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88e247d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101.0\n"
     ]
    }
   ],
   "source": [
    "res = get_fleet('route_id')\n",
    "\n",
    "df_route_id['fleet'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dc17813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101.0\n"
     ]
    }
   ],
   "source": [
    "res = get_fleet('route_type')\n",
    "\n",
    "df_route_type['fleet'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7743de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0a16eb3",
   "metadata": {},
   "source": [
    "# Line Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e08e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(col='route_id'):\n",
    "    link = links.groupby([col,'trip_id'])[[length_col]].agg(np.nansum)\n",
    "    return link.reset_index().groupby(col)[length_col].agg(np.nansum).to_dict()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfa2e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rpeparation. if legnth is NaN, or if shsape dist travel exist.\n",
    "\n",
    "length_col = None\n",
    "if 'length' in links.columns and length_col == None:\n",
    "    if len(links[links['length'].isnull()])==0:\n",
    "        length_col = 'length'\n",
    "        \n",
    "if 'shape_dist_traveled' in links.columns and length_col == None:\n",
    "    if len(links[links['shape_dist_traveled'].isnull()])==0:\n",
    "        length_col = 'shape_dist_traveled'\n",
    "\n",
    "if length_col == None:\n",
    "    print('create length from geometry')\n",
    "    links['length'] = links.to_crs(crs).length\n",
    "    length_col = 'length'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f7686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31db0758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194824\n"
     ]
    }
   ],
   "source": [
    "res = get_length('route_id')\n",
    "\n",
    "df_route_id['length (m)'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39826011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194824\n"
     ]
    }
   ],
   "source": [
    "res = get_length('route_type')\n",
    "\n",
    "df_route_type['length (m)'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4f68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "638013ee",
   "metadata": {},
   "source": [
    "# Number of station per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bf1bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o-->o-->o-->o and  o<--o<--o<--o\n",
    "# est-ce que j'ai 8 ou 4 stations ?\n",
    "# j'ai 4 stations par trip et 4 stations par route (si c'est les memes).\n",
    "# comment savoir si cest les memes. clustering?\n",
    "# pour linstant. on prend tous les noeds unique par route_id ou route_type (col='route_id', route_id)\n",
    "def get_num_station(col='route_id'):\n",
    "    link = links.groupby(col)[['a','b']].agg({'a':set,'b':set})\n",
    "    link['node_len'] = link.apply(lambda row: len(row['a'].union(row['b'])), axis=1)\n",
    "    return link['node_len'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f27ad9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774\n"
     ]
    }
   ],
   "source": [
    "res = get_num_station('route_id')\n",
    "\n",
    "df_route_id['num station'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea89801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774\n"
     ]
    }
   ],
   "source": [
    "res = get_num_station('route_type')\n",
    "\n",
    "df_route_type['num station'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f98a64c",
   "metadata": {},
   "source": [
    "# Vehicle revenue KM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c70257d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_veh_kmh(col='route_id'):\n",
    "    link = links.groupby([col,'trip_id'])[[length_col,'frequency']].agg({length_col:np.nansum,'frequency':np.nanmean})\n",
    "    link['veh_km/h'] = np.ceil(link['frequency'] * link[length_col]) * 3600/1000 #to km/H\n",
    "    return link.reset_index().groupby(col)['veh_km/h'].agg(np.nansum).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b53c067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1882.8000000000002\n"
     ]
    }
   ],
   "source": [
    "res = get_veh_kmh('route_id')\n",
    "\n",
    "df_route_id['veh.km/h'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3bc451d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1882.8000000000002\n"
     ]
    }
   ],
   "source": [
    "res = get_veh_kmh('route_type')\n",
    "\n",
    "df_route_type['veh.km/h'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab77743f",
   "metadata": {},
   "source": [
    "# Round trip time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd818c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_round_trip_time(col='route_id'):\n",
    "    link = links.groupby([col,'trip_id'])[['time']].agg(np.nansum)\n",
    "    return link.reset_index().groupby(col)['time'].agg(np.nansum).to_dict()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "869ea67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35058\n"
     ]
    }
   ],
   "source": [
    "res = get_round_trip_time('route_id')\n",
    "\n",
    "df_route_id['round trip time (s)'] = res\n",
    "print(sum([item for key,item in res.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6bf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a5213bf",
   "metadata": {},
   "source": [
    "# export dfs to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a7d0d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round numbers\n",
    "for col in ['catchment', 'frequency (veh/hours)','length (m)','veh.km/h','round trip time (s)']:\n",
    "    df_route_id[col] = df_route_id[col].apply(lambda x :np.round(x,2))\n",
    "    df_route_id[col] = df_route_id[col].apply(lambda x :np.round(x,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3105f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_route_id = df_route_id.fillna('null')\n",
    "#df_route_type = df_route_type.fillna('null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "984694c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catchment</th>\n",
       "      <th>frequency (veh/hours)</th>\n",
       "      <th>fleet</th>\n",
       "      <th>length (m)</th>\n",
       "      <th>num station</th>\n",
       "      <th>veh.km/h</th>\n",
       "      <th>round trip time (s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>route_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EDA5</th>\n",
       "      <td>12083.06</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9043</td>\n",
       "      <td>40</td>\n",
       "      <td>57.6</td>\n",
       "      <td>1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDA4</th>\n",
       "      <td>32273.57</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18038</td>\n",
       "      <td>56</td>\n",
       "      <td>111.6</td>\n",
       "      <td>3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDA3</th>\n",
       "      <td>28315.60</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16900</td>\n",
       "      <td>59</td>\n",
       "      <td>104.4</td>\n",
       "      <td>3041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDA2</th>\n",
       "      <td>36074.89</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16645</td>\n",
       "      <td>92</td>\n",
       "      <td>100.8</td>\n",
       "      <td>2996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDA1</th>\n",
       "      <td>18614.68</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12706</td>\n",
       "      <td>35</td>\n",
       "      <td>79.2</td>\n",
       "      <td>2284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R20</th>\n",
       "      <td>12789.23</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13208</td>\n",
       "      <td>35</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R19</th>\n",
       "      <td>22431.90</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6885</td>\n",
       "      <td>28</td>\n",
       "      <td>82.8</td>\n",
       "      <td>1238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R17</th>\n",
       "      <td>4924.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5622</td>\n",
       "      <td>13</td>\n",
       "      <td>68.4</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R16</th>\n",
       "      <td>9802.50</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11131</td>\n",
       "      <td>34</td>\n",
       "      <td>136.8</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R15</th>\n",
       "      <td>18618.13</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13895</td>\n",
       "      <td>39</td>\n",
       "      <td>169.2</td>\n",
       "      <td>2497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R13</th>\n",
       "      <td>8385.71</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4847</td>\n",
       "      <td>15</td>\n",
       "      <td>61.2</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R12</th>\n",
       "      <td>12266.56</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8613</td>\n",
       "      <td>22</td>\n",
       "      <td>104.4</td>\n",
       "      <td>1550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R11</th>\n",
       "      <td>30132.76</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14913</td>\n",
       "      <td>66</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R10</th>\n",
       "      <td>12648.23</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4832</td>\n",
       "      <td>18</td>\n",
       "      <td>61.2</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R09</th>\n",
       "      <td>16630.14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10152</td>\n",
       "      <td>35</td>\n",
       "      <td>122.4</td>\n",
       "      <td>1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R07</th>\n",
       "      <td>11274.35</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8954</td>\n",
       "      <td>28</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R06</th>\n",
       "      <td>6655.14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3109</td>\n",
       "      <td>15</td>\n",
       "      <td>39.6</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Route 3</th>\n",
       "      <td>32543.07</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11774</td>\n",
       "      <td>126</td>\n",
       "      <td>144.0</td>\n",
       "      <td>2116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R04</th>\n",
       "      <td>10710.68</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3557</td>\n",
       "      <td>18</td>\n",
       "      <td>43.2</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          catchment  frequency (veh/hours)  fleet  length (m)  num station  \\\n",
       "route_id                                                                     \n",
       "EDA5       12083.06                    6.0    3.0        9043           40   \n",
       "EDA4       32273.57                    6.0    6.0       18038           56   \n",
       "EDA3       28315.60                    6.0    6.0       16900           59   \n",
       "EDA2       36074.89                    6.0    5.0       16645           92   \n",
       "EDA1       18614.68                    6.0    4.0       12706           35   \n",
       "R20        12789.23                   12.0    8.0       13208           35   \n",
       "R19        22431.90                   12.0    5.0        6885           28   \n",
       "R17         4924.00                   12.0    4.0        5622           13   \n",
       "R16         9802.50                   12.0    7.0       11131           34   \n",
       "R15        18618.13                   12.0    9.0       13895           39   \n",
       "R13         8385.71                   12.0    3.0        4847           15   \n",
       "R12        12266.56                   12.0    6.0        8613           22   \n",
       "R11        30132.76                   12.0    9.0       14913           66   \n",
       "R10        12648.23                   12.0    3.0        4832           18   \n",
       "R09        16630.14                   12.0    7.0       10152           35   \n",
       "R07        11274.35                    6.0    3.0        8954           28   \n",
       "R06         6655.14                   12.0    2.0        3109           15   \n",
       "Route 3    32543.07                   12.0    8.0       11774          126   \n",
       "R04        10710.68                   12.0    3.0        3557           18   \n",
       "\n",
       "          veh.km/h  round trip time (s)  \n",
       "route_id                                 \n",
       "EDA5          57.6                 1630  \n",
       "EDA4         111.6                 3249  \n",
       "EDA3         104.4                 3041  \n",
       "EDA2         100.8                 2996  \n",
       "EDA1          79.2                 2284  \n",
       "R20          162.0                 2377  \n",
       "R19           82.8                 1238  \n",
       "R17           68.4                 1012  \n",
       "R16          136.8                 2006  \n",
       "R15          169.2                 2497  \n",
       "R13           61.2                  871  \n",
       "R12          104.4                 1550  \n",
       "R11          180.0                 2684  \n",
       "R10           61.2                  870  \n",
       "R09          122.4                 1825  \n",
       "R07           54.0                 1612  \n",
       "R06           39.6                  560  \n",
       "Route 3      144.0                 2116  \n",
       "R04           43.2                  640  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_route_id.to_csv(output_folder+'route_id_metrics.csv')\n",
    "df_route_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6a5c283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catchment</th>\n",
       "      <th>frequency (veh/hours)</th>\n",
       "      <th>fleet</th>\n",
       "      <th>length (m)</th>\n",
       "      <th>num station</th>\n",
       "      <th>veh.km/h</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>route_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NCD</th>\n",
       "      <td>97549.460998</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>73332</td>\n",
       "      <td>282</td>\n",
       "      <td>453.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMV</th>\n",
       "      <td>140758.291389</td>\n",
       "      <td>11.661088</td>\n",
       "      <td>77.0</td>\n",
       "      <td>121492</td>\n",
       "      <td>492</td>\n",
       "      <td>1429.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                catchment  frequency (veh/hours)  fleet  length (m)  \\\n",
       "route_type                                                            \n",
       "NCD          97549.460998               6.000000   24.0       73332   \n",
       "PMV         140758.291389              11.661088   77.0      121492   \n",
       "\n",
       "            num station  veh.km/h  \n",
       "route_type                         \n",
       "NCD                 282     453.6  \n",
       "PMV                 492    1429.2  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_route_type.to_csv(output_folder+'route_type_metrics.csv')\n",
    "df_route_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad4b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc7238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0c4f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4924d2a1",
   "metadata": {},
   "source": [
    "# geomatic outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "10166c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using get catchment. get the catchment radius of each node (get larger one if used by many mode.)\n",
    "link = links.groupby('route_type')[['a','b','route_type']].agg({'a':set,'b':set,'route_type':'first'})\n",
    "link['node'] = link.apply(lambda row: row['a'].union(row['b']), axis=1)\n",
    "link = link.drop(columns=['a','b'])\n",
    "# add catchment radius for the route_type\n",
    "link['catchment_radius'] = link['route_type'].apply(lambda x: catchment_radius.get(x,default_catchment_radius))\n",
    "link = link.explode('node').reset_index(drop=True)\n",
    "link = link.sort_values('catchment_radius',ascending=False).drop_duplicates('node',keep='first')\n",
    "link = node_dist.merge(link, left_on='node_index', right_on='node')\n",
    "link = link[link['distances'] <= link['catchment_radius']]\n",
    "\n",
    "temp_dict = link.groupby('node_index')['population'].sum().to_dict()\n",
    "nodes['catchment'] = nodes.index.map(temp_dict.get)\n",
    "\n",
    "temp_dict = link.groupby('node_index')['catchment_radius'].agg('first').to_dict() \n",
    "nodes['catchment_radius'] = nodes.index.map(temp_dict.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db8164da",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.to_file(output_folder+'nodes.geojson',driver='GeoJSON',engine=io_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dfe2fb",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400b2a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b702f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quetzal_env",
   "language": "python",
   "name": "quetzal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
